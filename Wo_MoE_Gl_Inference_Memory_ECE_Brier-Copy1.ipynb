{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94911859-00eb-4615-a50f-a13fc06303e2",
   "metadata": {},
   "source": [
    "# W/o_MoE_GL_Inference_Memory_ECE_Brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ced44-9a92-49ce-beae-7040ac71535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths for different expert datasets and models\n",
    "expert_configs = {\n",
    "    \"alpaca\": {\n",
    "        \"adapter_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-Alpaca/results/alpaca_adapter/adapter_model.safetensors\",\n",
    "        \"gamma\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-Alpaca/results/alpaca_adapter/adapter_config.json\",\n",
    "        \"base_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-Alpaca/base_model_weights.pth\",\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/Alpaca/Alpaca_Train.json\",\n",
    "        \"test_data\": \"/kaggle/input/worksapce/orkspace/Dataset/Alpaca/Alpaca_Test.json\"\n",
    "    },\n",
    "    \"beavertails\": {\n",
    "        \"adapter_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-BeaverTails/results/beavertails_adapter/adapter_model.safetensors\",\n",
    "        \"gamma\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-BeaverTails/results/beavertails_adapter/adapter_config.json\",\n",
    "        \"base_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-BeaverTails/base_model_weights.pth\",\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/BeaverTails/BeaverTails_Train.csv\",\n",
    "        \"test_data\": \"/kaggle/input/worksapce/orkspace/Dataset/BeaverTails/BeaverTails_Test.csv\"\n",
    "    },\n",
    "    \"truthfulqa\": {\n",
    "        \"adapter_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7b-TruthfulQA/results/truthfulqa_adapter/adapter_model.safetensors\",\n",
    "        \"gamma\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7b-TruthfulQA/results/truthfulqa_adapter/adapter_config.json\",\n",
    "        \"base_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7b-TruthfulQA/base_model_weights.pth\",\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/TruthfulQA/TruthfulQA_Train.csv\",\n",
    "        \"test_data\":  \"/kaggle/input/worksapce/orkspace/Dataset/TruthfulQA/TruthfulQA_Test.csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define Feed Forward Network (FFN) for each expert\n",
    "class ExpertFFN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "\n",
    "def text_to_numeric(text_series):\n",
    "    \"\"\"Convert text data into TF-IDF numerical vectors.\"\"\"\n",
    "    return vectorizer.fit_transform(text_series).toarray()\n",
    "\n",
    "def load_data(expert_name):\n",
    "    \"\"\"Load and vectorize train/test for a given expert.\"\"\"\n",
    "    paths = expert_configs[expert_name]\n",
    "    \n",
    "    if paths[\"train_data\"].endswith(\".json\"):\n",
    "        train = pd.read_json(paths[\"train_data\"])\n",
    "        test  = pd.read_json(paths[\"test_data\"])\n",
    "    else:\n",
    "        train = pd.read_csv(paths[\"train_data\"])\n",
    "        test  = pd.read_csv(paths[\"test_data\"])\n",
    "\n",
    "    # If there's a text column, vectorize the first one\n",
    "    txt_cols = train.select_dtypes(include=['object']).columns\n",
    "    if len(txt_cols) > 0:\n",
    "        train = pd.DataFrame(text_to_numeric(train[txt_cols[0]]))\n",
    "        test  = pd.DataFrame(text_to_numeric(test[txt_cols[0]]))\n",
    "\n",
    "    return train.select_dtypes(include=['number']), test.select_dtypes(include=['number'])\n",
    "\n",
    "# Load experts\n",
    "experts = {}\n",
    "for name in expert_configs:\n",
    "    tr, te = load_data(name)\n",
    "    dim   = tr.shape[1] if tr.shape[1] > 0 else 1\n",
    "    experts[name] = {\n",
    "        \"ffn\":       ExpertFFN(input_dim=dim, hidden_dim=128, output_dim=64),\n",
    "        \"train_data\": tr,\n",
    "        \"test_data\":  te\n",
    "    }\n",
    "\n",
    "def entropy_regularization(probs):\n",
    "    return -torch.sum(probs * torch.log(probs + 1e-8))\n",
    "\n",
    "def kl_divergence(p, q, epsilon=1e-8):\n",
    "    p = torch.clamp(p, min=epsilon)\n",
    "    q = torch.clamp(q, min=epsilon)\n",
    "    return torch.sum(p * torch.log(p / q))\n",
    "\n",
    "def update_gamma_values(gamma_values, expert_losses, scaling_factor=0.1):\n",
    "    updated = {}\n",
    "    total_loss = sum(expert_losses.values())\n",
    "    for exp, loss in expert_losses.items():\n",
    "        updated[exp] = gamma_values[exp] * (total_loss / (loss + 1e-8)) * scaling_factor\n",
    "    norm = sum(updated.values())\n",
    "    return {k: v / norm for k, v in updated.items()}\n",
    "\n",
    "# Router with gating loss but no temperature\n",
    "class MoCaERouterWithGating(nn.Module):\n",
    "    def __init__(self, expert_ffns, gamma_values, previous_gamma_values=None):\n",
    "        super().__init__()\n",
    "        self.expert_ffns = expert_ffns\n",
    "        self.gamma_values = gamma_values\n",
    "        self.previous_gamma_values = previous_gamma_values or gamma_values\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1) plain softmax over gamma\n",
    "        gamma_tensor = torch.tensor(list(self.gamma_values.values()), dtype=torch.float32)\n",
    "        gamma_scaled = F.softmax(gamma_tensor, dim=0)\n",
    "\n",
    "        # 2) weighted expert outputs\n",
    "        outs = {\n",
    "            e: ffn(x) * gamma_scaled[i]\n",
    "            for i, (e, ffn) in enumerate(self.expert_ffns.items())\n",
    "        }\n",
    "        weighted_sum = sum(outs.values())\n",
    "\n",
    "        # 3) penalties\n",
    "        entropy   = entropy_regularization(gamma_scaled)\n",
    "        kl_pen    = kl_divergence(\n",
    "            gamma_scaled,\n",
    "            torch.tensor(list(self.previous_gamma_values.values()), dtype=torch.float32)\n",
    "        )\n",
    "        # 4) gating loss = KL( gamma_scaled ‖ uniform )\n",
    "        num_experts = len(gamma_scaled)\n",
    "        uniform     = torch.full((num_experts,), 1.0 / num_experts)\n",
    "        gating_loss = kl_divergence(gamma_scaled, uniform)\n",
    "\n",
    "        # 5) update state\n",
    "        self.previous_gamma_values = self.gamma_values\n",
    "\n",
    "        # 6) total loss\n",
    "        total_loss = (\n",
    "            torch.mean(weighted_sum)\n",
    "            + 0.1  * entropy\n",
    "            + 0.01 * kl_pen\n",
    "            + 0.05 * gating_loss\n",
    "        )\n",
    "\n",
    "        # 7) update gamma for next step\n",
    "        expert_losses = {e: total_loss.item() for e in self.expert_ffns}\n",
    "        self.gamma_values = update_gamma_values(self.gamma_values, expert_losses)\n",
    "\n",
    "        return total_loss, weighted_sum, entropy, kl_pen, gating_loss\n",
    "\n",
    "# Initialize router\n",
    "expert_ffns  = {n: experts[n][\"ffn\"] for n in experts}\n",
    "gamma_values = {n: 1.0 for n in experts}\n",
    "router       = MoCaERouterWithGating(expert_ffns, gamma_values)\n",
    "\n",
    "def process_input_data():\n",
    "    \"\"\"Run each expert’s train_data through the router and print all losses.\"\"\"\n",
    "    for exp, vals in experts.items():\n",
    "        df = vals[\"train_data\"]\n",
    "        if df.empty:\n",
    "            print(f\"Skipping {exp}: No numeric data!\")\n",
    "            continue\n",
    "\n",
    "        emb = torch.tensor(df.values, dtype=torch.float32)\n",
    "        loss, ws, ent, klp, gl = router(emb)\n",
    "        print(\n",
    "            f\"{exp} → \"\n",
    "            f\"Loss: {loss.item():.4f}, \"\n",
    "            f\"Entropy: {ent.item():.4f}, \"\n",
    "            f\"KL: {klp.item():.4f}, \"\n",
    "            f\"Gating: {gl.item():.4f}\"\n",
    "        )\n",
    "\n",
    "process_input_data()\n",
    "\n",
    "def save_aggregated_output_embeddings():\n",
    "    \"\"\"Save weighted_sum for each expert to disk.\"\"\"\n",
    "    agg = {}\n",
    "    for exp, vals in experts.items():\n",
    "        df = vals[\"train_data\"]\n",
    "        if df.empty:\n",
    "            continue\n",
    "        emb = torch.tensor(df.values, dtype=torch.float32)\n",
    "        _, ws, _, _, _ = router(emb)\n",
    "        agg[exp] = ws.detach().cpu().numpy()\n",
    "\n",
    "    out_dir = '/workspace/Dataset/aggregated_embeddings'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    np.save(os.path.join(out_dir, 'aggregated_embeddings.npy'), agg)\n",
    "    print(\"Aggregated embeddings saved.\")\n",
    "\n",
    "save_aggregated_output_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2fa8d3-1a90-4151-baa1-65cdc744659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the aggregated embeddings\n",
    "def check_aggregated_embeddings_shape(file_path):\n",
    "    \"\"\"Load the aggregated embeddings and print their shape.\"\"\"\n",
    "    # Load the embeddings from the saved .npy file\n",
    "    aggregated_embeddings = np.load(file_path, allow_pickle=True).item()\n",
    "    \n",
    "    # Print the shape of each expert's aggregated embedding\n",
    "    for expert, embedding in aggregated_embeddings.items():\n",
    "        print(f\"Shape of {expert}'s aggregated embedding: {embedding.shape}\")\n",
    "\n",
    "# Path to the saved aggregated embeddings file\n",
    "aggregated_embeddings_file = '/kaggle/input/worksapce/workspace/orkspace/Dataset/aggregated_embeddings/aggregated_embeddings.npy'\n",
    "\n",
    "# Check the shape of the aggregated embeddings\n",
    "check_aggregated_embeddings_shape(aggregated_embeddings_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2335e0a-e329-4d81-8b73-925abffb7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# --------------------\n",
    "# Config & Paths\n",
    "# --------------------\n",
    "expert_configs = {\n",
    "    \"alpaca\": {\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/Alpaca/Alpaca_Train.json\"\n",
    "    },\n",
    "    \"beavertails\": {\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/BeaverTails/BeaverTails_Train.csv\"\n",
    "    },\n",
    "    \"truthfulqa\": {\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/TruthfulQA/TruthfulQA_Train.csv\"\n",
    "    },\n",
    "    \n",
    "}\n",
    "EMBEDDINGS_FILE = '/workspace/Dataset/aggregated_embeddings/aggregated_embeddings.npy'\n",
    "\n",
    "# --------------------\n",
    "# Label Loader with Safe Fallback\n",
    "# --------------------\n",
    "def load_labels(expert_name, label_col='label'):\n",
    "    path = expert_configs[expert_name]['train_data']\n",
    "    if path is None:\n",
    "        raise KeyError(f\"No train_data path for {expert_name}\")\n",
    "    df = pd.read_json(path) if path.endswith('.json') else pd.read_csv(path)\n",
    "    if label_col in df.columns:\n",
    "        return df[label_col].values\n",
    "    # Try inferring label column: integer dtype with few unique values\n",
    "    int_cols = [c for c in df.columns if pd.api.types.is_integer_dtype(df[c])]\n",
    "    for c in int_cols:\n",
    "        if df[c].nunique() < len(df) / 2:\n",
    "            print(f\"Info: Using inferred label column '{c}' for {expert_name}\")\n",
    "            return df[c].values\n",
    "    # No suitable label found\n",
    "    raise KeyError(f\"No label column found for {expert_name} in {path}\")\n",
    "\n",
    "# --------------------\n",
    "# Calibration & Scoring Metrics\n",
    "# --------------------\n",
    "\n",
    "def compute_ece(probs, labels, n_bins=10):\n",
    "    bins = np.linspace(0,1,n_bins+1)\n",
    "    confidences = np.max(probs, axis=1)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    acc = (preds == labels).astype(float)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
    "        if mask.any():\n",
    "            ece += abs(confidences[mask].mean() - acc[mask].mean()) * mask.sum() / len(labels)\n",
    "    return ece\n",
    "\n",
    "\n",
    "def compute_brier(probs, labels):\n",
    "    N, C = probs.shape\n",
    "    true_onehot = np.zeros_like(probs)\n",
    "    true_onehot[np.arange(N), labels] = 1\n",
    "    return np.mean(np.sum((probs - true_onehot)**2, axis=1))\n",
    "\n",
    "\n",
    "def temperature_scale(probs, temperature=1.0):\n",
    "    logits = np.log(np.clip(probs, 1e-12, 1.0)) / temperature\n",
    "    exp = np.exp(logits)\n",
    "    return exp / exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "# --------------------\n",
    "# Zero-Shot & Few-Shot Evaluation\n",
    "# --------------------\n",
    "\n",
    "def eval_zero_shot(embeddings, labels, temp=1.0):\n",
    "    # Inference timing\n",
    "    start = time.time()\n",
    "    logits = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    probs = torch.softmax(logits, dim=1).numpy()\n",
    "    infer_time = time.time() - start\n",
    "\n",
    "    # Metrics\n",
    "    ece = compute_ece(probs, labels)\n",
    "    ece_t = compute_ece(temperature_scale(probs, temp), labels)\n",
    "    brier = compute_brier(probs, labels)\n",
    "\n",
    "    return {\n",
    "        'ECE': round(ece,4),\n",
    "        'ECE-t': round(ece_t,4),\n",
    "        'Brier': round(brier,4),\n",
    "        'Inference_Time_s': round(infer_time,4),\n",
    "        'Train_Time_s': 0.0,\n",
    "        'Train_Memory_MB': 0.0\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_few_shot(embeddings, labels, epochs=5, temp=1.0, device='cpu'):\n",
    "    X = torch.tensor(embeddings, dtype=torch.float32).to(device)\n",
    "    y = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "    num_classes = len(np.unique(labels))\n",
    "    model = nn.Linear(embeddings.shape[1], num_classes).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training timing & memory\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = crit(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_time = time.time() - t0\n",
    "    train_mem = psutil.Process(os.getpid()).memory_info().rss / 1024**2\n",
    "\n",
    "    # Inference\n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "    infer_time = time.time() - t1\n",
    "\n",
    "    # Metrics\n",
    "    ece = compute_ece(probs, labels)\n",
    "    ece_t = compute_ece(temperature_scale(probs, temp), labels)\n",
    "    brier = compute_brier(probs, labels)\n",
    "\n",
    "    return {\n",
    "        'ECE': round(ece,4),\n",
    "        'ECE-t': round(ece_t,4),\n",
    "        'Brier': round(brier,4),\n",
    "        'Inference_Time_s': round(infer_time,4),\n",
    "        'Train_Time_s': round(train_time,4),\n",
    "        'Train_Memory_MB': round(train_mem,4)\n",
    "    }\n",
    "\n",
    "# --------------------\n",
    "# Main Loop\n",
    "# --------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    agg = np.load(EMBEDDINGS_FILE, allow_pickle=True).item()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    for expert, emb in agg.items():\n",
    "        print(f\"--- {expert.upper()} ---\")\n",
    "        try:\n",
    "            labels = load_labels(expert)\n",
    "        except KeyError as e:\n",
    "            print(f\"Skipping '{expert}': {e}\")\n",
    "            continue\n",
    "\n",
    "        zero = eval_zero_shot(emb, labels)\n",
    "        few = eval_few_shot(emb, labels, epochs=5, device=device)\n",
    "\n",
    "        print(\"Zero-Shot Metrics:\")\n",
    "        for k,v in zero.items(): print(f\"  {k}: {v}\")\n",
    "        print(\"Few-Shot Metrics:\")\n",
    "        for k,v in few.items(): print(f\"  {k}: {v}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd06c23-8290-484a-ba83-1da398a205f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
