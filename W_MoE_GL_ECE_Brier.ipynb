{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ad1c75-18f4-4f45-bdcf-7395938708fe",
   "metadata": {},
   "source": [
    "# W_MoE_GL_Inference_Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ced44-9a92-49ce-beae-7040ac71535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "expert_configs = {\n",
    "    \"alpaca\": {\n",
    "        \"adapter_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-Alpaca/results/alpaca_adapter/adapter_model.safetensors\",\n",
    "        \"gamma\":           \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-Alpaca/results/alpaca_adapter/adapter_config.json\",\n",
    "        \"base_weights\":    \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-Alpaca/base_model_weights.pth\",\n",
    "        \"train_data\":      \"/kaggle/input/worksapce/orkspace/Dataset/Alpaca/Alpaca_Train.json\",\n",
    "        \"test_data\":       \"/kaggle/input/worksapce/orkspace/Dataset/Alpaca/Alpaca_Test.json\"\n",
    "    },\n",
    "    \"beavertails\": {\n",
    "        \"adapter_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-BeaverTails/results/beavertails_adapter/adapter_model.safetensors\",\n",
    "        \"gamma\":           \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-BeaverTails/results/beavertails_adapter/adapter_config.json\",\n",
    "        \"base_weights\":    \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-BeaverTails/base_model_weights.pth\",\n",
    "        \"train_data\":      \"/kaggle/input/worksapce/orkspace/Dataset/BeaverTails/BeaverTails_Train.csv\",\n",
    "        \"test_data\":       \"/kaggle/input/worksapce/orkspace/Dataset/BeaverTails/BeaverTails_Test.csv\"\n",
    "    },\n",
    "    \"truthfulqa\": {\n",
    "        \"adapter_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7b-TruthfulQA/results/truthfulqa_adapter/adapter_model.safetensors\",\n",
    "        \"gamma\":           \"/kaggle/input/worksapce/orkspace/LLaMa-2-7b-TruthfulQA/results/truthfulqa_adapter/adapter_config.json\",\n",
    "        \"base_weights\":    \"/kaggle/input/worksapce/orkspace/LLaMa-2-7b-TruthfulQA/base_model_weights.pth\",\n",
    "        \"train_data\":      \"/kaggle/input/worksapce/orkspace/Dataset/TruthfulQA/TruthfulQA_Train.csv\",\n",
    "        \"test_data\":       \"/kaggle/input/worksapce/orkspace/Dataset/TruthfulQA/TruthfulQA_Test.csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# FFN definition\n",
    "class ExpertFFN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.activation(self.fc1(x)))\n",
    "\n",
    "# TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "\n",
    "def text_to_numeric(series):\n",
    "    return vectorizer.fit_transform(series).toarray()\n",
    "\n",
    "# Load data\n",
    "def load_data(name):\n",
    "    p = expert_configs[name]\n",
    "    if p['train_data'].endswith('.json'):\n",
    "        td = pd.read_json(p['train_data'])\n",
    "        vd = pd.read_json(p['test_data'])\n",
    "    else:\n",
    "        td = pd.read_csv(p['train_data'])\n",
    "        vd = pd.read_csv(p['test_data'])\n",
    "    col = td.select_dtypes(include=['object']).columns\n",
    "    if len(col):\n",
    "        td = pd.DataFrame(text_to_numeric(td[col[0]]))\n",
    "        vd = pd.DataFrame(text_to_numeric(vd[col[0]]))\n",
    "    return td.select_dtypes(include=['number']), vd.select_dtypes(include=['number'])\n",
    "\n",
    "# Initialize experts\n",
    "experts = {}\n",
    "for name in expert_configs:\n",
    "    td, vd = load_data(name)\n",
    "    dim = td.shape[1] if td.shape[1]>0 else 1\n",
    "    experts[name] = {'ffn': ExpertFFN(dim,128,64), 'train_data': td, 'test_data': vd}\n",
    "\n",
    "# Temperature-scaled softmax\n",
    "def temperature_scaled_softmax(gv, temp=0.7):\n",
    "    t = torch.tensor(list(gv.values()), dtype=torch.float32)\n",
    "    probs = F.softmax(t/temp, dim=0)\n",
    "    return {k: v.item() for k,v in zip(gv.keys(), probs)}\n",
    "\n",
    "# Entropy reg & KL\n",
    "def entropy_regularization(p): return -torch.sum(p*torch.log(p+1e-8))\n",
    "def kl_divergence(p,q,eps=1e-8): return torch.sum(p*torch.log(p/q))\n",
    "\n",
    "def update_gamma_values(gv, losses, sf=0.1):\n",
    "    up = {}; tot = sum(losses.values())\n",
    "    for e,l in losses.items(): up[e] = gv[e]*(tot/(l+1e-8))*sf\n",
    "    s = sum(up.values()); return {k:v/s for k,v in up.items()}\n",
    "\n",
    "# Router with gating loss\n",
    "class MoCaERouterWithPenalties(nn.Module):\n",
    "    def __init__(self, ffns, gv, prev=None, temp=0.7):\n",
    "        super().__init__(); self.ffns=ffns; self.gamma_values=gv; self.previous_gamma_values=prev or gv; self.temperature=temp\n",
    "    def forward(self,x):\n",
    "        gs = temperature_scaled_softmax(self.gamma_values, self.temperature)\n",
    "        outs = {e:fn(x)*gs[e] for e,fn in self.ffns.items()}\n",
    "        wsum = sum(outs.values())\n",
    "        ent = entropy_regularization(torch.tensor(list(gs.values())))\n",
    "        klp = kl_divergence(torch.tensor(list(gs.values())), torch.tensor(list(self.previous_gamma_values.values())))\n",
    "        num = len(gs); uni = torch.full((num,),1.0/num)\n",
    "        gl = kl_divergence(torch.tensor(list(gs.values())), uni)\n",
    "        self.previous_gamma_values = self.gamma_values\n",
    "        total = torch.mean(wsum) + 0.1*ent + 0.01*klp + 0.05*gl\n",
    "        losses = {e: total.item() for e in self.ffns}\n",
    "        self.gamma_values = update_gamma_values(self.gamma_values, losses)\n",
    "        return total, wsum, ent, klp\n",
    "\n",
    "# Initialize router\n",
    "ep_ffns = {n: experts[n]['ffn'] for n in experts}\n",
    "gamma_values = {n:1.0 for n in experts}\n",
    "router = MoCaERouterWithPenalties(ep_ffns, gamma_values)\n",
    "\n",
    "# Process\n",
    "def process_input_data_with_penalties():\n",
    "    for e,v in experts.items():\n",
    "        df=v['train_data']\n",
    "        if df.empty: print(f\"Skipping {e}\"); continue\n",
    "        t=torch.tensor(df.values, dtype=torch.float32)\n",
    "        L,WS,Ent,KL=router(t)\n",
    "        print(f\"Processed {e} - Loss:{L.item():.4f} Ent:{Ent.item():.4f} KL:{KL.item():.4f}\")\n",
    "process_input_data_with_penalties()\n",
    "\n",
    "# Save aggregated embeddings both locally and to Kaggle output\n",
    "def save_aggregated_output_embeddings():\n",
    "    agg={}\n",
    "    for e,v in experts.items():\n",
    "        df=v['train_data']\n",
    "        if df.empty: continue\n",
    "        t=torch.tensor(df.values, dtype=torch.float32)\n",
    "        _,WS,_,_ = router(t)\n",
    "        agg[e]=WS.detach().cpu().numpy()\n",
    "    # local path\n",
    "    local='/workspace/Dataset/aggregated_embeddings'\n",
    "    os.makedirs(local,exist_ok=True)\n",
    "    lp=os.path.join(local,'aggregated_embeddingsmoe_gl.npy')\n",
    "    np.save(lp,agg)\n",
    "    print(f\"Saved to {lp}\")\n",
    "    # Kaggle output\n",
    "    kop='/kaggle/working/aggregated_embeddingsmoe_gl.npy'\n",
    "    np.save(kop,agg)\n",
    "    print(f\"Also saved to {kop}\")\n",
    "save_aggregated_output_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9d678-5dfd-4fe7-90a5-752670da70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the aggregated embeddings\n",
    "def check_aggregated_embeddings_shape(file_path):\n",
    "    \"\"\"Load the aggregated embeddings and print their shape.\"\"\"\n",
    "    # Load the embeddings from the saved .npy file\n",
    "    aggregated_embeddings = np.load(file_path, allow_pickle=True).item()\n",
    "    \n",
    "    # Print the shape of each expert's aggregated embedding\n",
    "    for expert, embedding in aggregated_embeddings.items():\n",
    "        print(f\"Shape of {expert}'s aggregated embedding: {embedding.shape}\")\n",
    "\n",
    "# Path to the saved aggregated embeddings file\n",
    "aggregated_embeddings_file = '/kaggle/input/worksapce/workspace/orkspace/Dataset/aggregated_embeddings/aggregated_embeddings.npy'\n",
    "\n",
    "# Check the shape of the aggregated embeddings\n",
    "check_aggregated_embeddings_shape(aggregated_embeddings_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a0c3a-97e4-422e-81d4-22ab19c8c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# --------------------\n",
    "# Config & Paths\n",
    "# --------------------\n",
    "expert_configs = {\n",
    "    \"alpaca\": {\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/Alpaca/Alpaca_Train.json\"\n",
    "    },\n",
    "    \"beavertails\": {\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/BeaverTails/BeaverTails_Train.csv\"\n",
    "    },\n",
    "    \"truthfulqa\": {\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/TruthfulQA/TruthfulQA_Train.csv\"\n",
    "    },\n",
    "    \n",
    "}\n",
    "EMBEDDINGS_FILE = '/workspace/Dataset/aggregated_embeddings/aggregated_embeddings.npy'\n",
    "\n",
    "# --------------------\n",
    "# Label Loader with Safe Fallback\n",
    "# --------------------\n",
    "def load_labels(expert_name, label_col='label'):\n",
    "    path = expert_configs[expert_name]['train_data']\n",
    "    if path is None:\n",
    "        raise KeyError(f\"No train_data path for {expert_name}\")\n",
    "    df = pd.read_json(path) if path.endswith('.json') else pd.read_csv(path)\n",
    "    if label_col in df.columns:\n",
    "        return df[label_col].values\n",
    "    # Try inferring label column: integer dtype with few unique values\n",
    "    int_cols = [c for c in df.columns if pd.api.types.is_integer_dtype(df[c])]\n",
    "    for c in int_cols:\n",
    "        if df[c].nunique() < len(df) / 2:\n",
    "            print(f\"Info: Using inferred label column '{c}' for {expert_name}\")\n",
    "            return df[c].values\n",
    "    # No suitable label found\n",
    "    raise KeyError(f\"No label column found for {expert_name} in {path}\")\n",
    "\n",
    "# --------------------\n",
    "# Calibration & Scoring Metrics\n",
    "# --------------------\n",
    "\n",
    "def compute_ece(probs, labels, n_bins=10):\n",
    "    bins = np.linspace(0,1,n_bins+1)\n",
    "    confidences = np.max(probs, axis=1)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    acc = (preds == labels).astype(float)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
    "        if mask.any():\n",
    "            ece += abs(confidences[mask].mean() - acc[mask].mean()) * mask.sum() / len(labels)\n",
    "    return ece\n",
    "\n",
    "\n",
    "def compute_brier(probs, labels):\n",
    "    N, C = probs.shape\n",
    "    true_onehot = np.zeros_like(probs)\n",
    "    true_onehot[np.arange(N), labels] = 1\n",
    "    return np.mean(np.sum((probs - true_onehot)**2, axis=1))\n",
    "\n",
    "\n",
    "def temperature_scale(probs, temperature=1.0):\n",
    "    logits = np.log(np.clip(probs, 1e-12, 1.0)) / temperature\n",
    "    exp = np.exp(logits)\n",
    "    return exp / exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "# --------------------\n",
    "# Zero-Shot & Few-Shot Evaluation\n",
    "# --------------------\n",
    "\n",
    "def eval_zero_shot(embeddings, labels, temp=1.0):\n",
    "    # Inference timing\n",
    "    start = time.time()\n",
    "    logits = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    probs = torch.softmax(logits, dim=1).numpy()\n",
    "    infer_time = time.time() - start\n",
    "\n",
    "    # Metrics\n",
    "    ece = compute_ece(probs, labels)\n",
    "    ece_t = compute_ece(temperature_scale(probs, temp), labels)\n",
    "    brier = compute_brier(probs, labels)\n",
    "\n",
    "    return {\n",
    "        'ECE': round(ece,4),\n",
    "        'ECE-t': round(ece_t,4),\n",
    "        'Brier': round(brier,4),\n",
    "        'Inference_Time_s': round(infer_time,4),\n",
    "        'Train_Time_s': 0.0,\n",
    "        'Train_Memory_MB': 0.0\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_few_shot(embeddings, labels, epochs=5, temp=1.0, device='cpu'):\n",
    "    X = torch.tensor(embeddings, dtype=torch.float32).to(device)\n",
    "    y = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "    num_classes = len(np.unique(labels))\n",
    "    model = nn.Linear(embeddings.shape[1], num_classes).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training timing & memory\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = crit(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_time = time.time() - t0\n",
    "    train_mem = psutil.Process(os.getpid()).memory_info().rss / 1024**2\n",
    "\n",
    "    # Inference\n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "    infer_time = time.time() - t1\n",
    "\n",
    "    # Metrics\n",
    "    ece = compute_ece(probs, labels)\n",
    "    ece_t = compute_ece(temperature_scale(probs, temp), labels)\n",
    "    brier = compute_brier(probs, labels)\n",
    "\n",
    "    return {\n",
    "        'ECE': round(ece,4),\n",
    "        'ECE-t': round(ece_t,4),\n",
    "        'Brier': round(brier,4),\n",
    "        'Inference_Time_s': round(infer_time,4),\n",
    "        'Train_Time_s': round(train_time,4),\n",
    "        'Train_Memory_MB': round(train_mem,4)\n",
    "    }\n",
    "\n",
    "# --------------------\n",
    "# Main Loop\n",
    "# --------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    agg = np.load(EMBEDDINGS_FILE, allow_pickle=True).item()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    for expert, emb in agg.items():\n",
    "        print(f\"--- {expert.upper()} ---\")\n",
    "        try:\n",
    "            labels = load_labels(expert)\n",
    "        except KeyError as e:\n",
    "            print(f\"Skipping '{expert}': {e}\")\n",
    "            continue\n",
    "\n",
    "        zero = eval_zero_shot(emb, labels)\n",
    "        few = eval_few_shot(emb, labels, epochs=5, device=device)\n",
    "\n",
    "        print(\"Zero-Shot Metrics:\")\n",
    "        for k,v in zero.items(): print(f\"  {k}: {v}\")\n",
    "        print(\"Few-Shot Metrics:\")\n",
    "        for k,v in few.items(): print(f\"  {k}: {v}\")\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
