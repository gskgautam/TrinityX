{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94911859-00eb-4615-a50f-a13fc06303e2",
   "metadata": {},
   "source": [
    "# W/o_MoE_GL_RL_Inference_Memory_ECE_Brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ced44-9a92-49ce-beae-7040ac71535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths for different expert datasets and models\n",
    "expert_configs = {\n",
    "    \"alpaca\": {\n",
    "        \"adapter_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-Alpaca/results/alpaca_adapter/adapter_model.safetensors\",\n",
    "        \"gamma\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-Alpaca/results/alpaca_adapter/adapter_config.json\",\n",
    "        \"base_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-Alpaca/base_model_weights.pth\",\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/Alpaca/Alpaca_Train.json\",\n",
    "        \"test_data\": \"/kaggle/input/worksapce/orkspace/Dataset/Alpaca/Alpaca_Test.json\"\n",
    "    },\n",
    "    \"beavertails\": {\n",
    "        \"adapter_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-BeaverTails/results/beavertails_adapter/adapter_model.safetensors\",\n",
    "        \"gamma\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-BeaverTails/results/beavertails_adapter/adapter_config.json\",\n",
    "        \"base_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7B-BeaverTails/base_model_weights.pth\",\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/BeaverTails/BeaverTails_Train.csv\",\n",
    "        \"test_data\": \"/kaggle/input/worksapce/orkspace/Dataset/BeaverTails/BeaverTails_Test.csv\"\n",
    "    },\n",
    "    \"truthfulqa\": {\n",
    "        \"adapter_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7b-TruthfulQA/results/truthfulqa_adapter/adapter_model.safetensors\",\n",
    "        \"gamma\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7b-TruthfulQA/results/truthfulqa_adapter/adapter_config.json\",\n",
    "        \"base_weights\": \"/kaggle/input/worksapce/orkspace/LLaMa-2-7b-TruthfulQA/base_model_weights.pth\",\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/TruthfulQA/TruthfulQA_Train.csv\",\n",
    "        \"test_data\":  \"/kaggle/input/worksapce/orkspace/Dataset/TruthfulQA/TruthfulQA_Test.csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Feed-Forward Expert ===\n",
    "class ExpertFFN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.act = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.act(self.fc1(x)))\n",
    "\n",
    "# === TF-IDF Vectorizer ===\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "def text_to_numeric(series):\n",
    "    return vectorizer.fit_transform(series).toarray()\n",
    "\n",
    "def load_data(name):\n",
    "    p = expert_configs[name]\n",
    "    if p[\"train_data\"].endswith(\".json\"):\n",
    "        tr = pd.read_json(p[\"train_data\"])\n",
    "        te = pd.read_json(p[\"test_data\"])\n",
    "    else:\n",
    "        tr = pd.read_csv(p[\"train_data\"])\n",
    "        te = pd.read_csv(p[\"test_data\"])\n",
    "    txt = tr.select_dtypes(include=['object']).columns\n",
    "    if len(txt):\n",
    "        tr = pd.DataFrame(text_to_numeric(tr[txt[0]]))\n",
    "        te = pd.DataFrame(text_to_numeric(te[txt[0]]))\n",
    "    return tr.select_dtypes(include='number'), te.select_dtypes(include='number')\n",
    "\n",
    "# === Load experts and their data ===\n",
    "experts = {}\n",
    "for name in expert_configs:\n",
    "    tr, te = load_data(name)\n",
    "    dim = tr.shape[1] or 1\n",
    "    experts[name] = {\n",
    "        \"ffn\": ExpertFFN(dim, 128, 64),\n",
    "        \"train_data\": tr,\n",
    "        \"test_data\": te\n",
    "    }\n",
    "\n",
    "# === Loss utilities ===\n",
    "def entropy_regularization(p):\n",
    "    return -torch.sum(p * torch.log(p + 1e-8))\n",
    "\n",
    "def kl_divergence(p, q, eps=1e-8):\n",
    "    p = torch.clamp(p, min=eps)\n",
    "    q = torch.clamp(q, min=eps)\n",
    "    return torch.sum(p * torch.log(p / q))\n",
    "\n",
    "def update_gamma_values(gamma_values, losses, scaling_factor=0.1):\n",
    "    updated = {}\n",
    "    total = sum(losses.values())\n",
    "    for e, l in losses.items():\n",
    "        updated[e] = gamma_values[e] * (total / (l + 1e-8)) * scaling_factor\n",
    "    norm = sum(updated.values())\n",
    "    return {e: v / norm for e, v in updated.items()}\n",
    "\n",
    "# === Router with Gating + RL (no calibration) ===\n",
    "class MoCaERouterWithGatingAndRL(nn.Module):\n",
    "    def __init__(self, expert_ffns, gamma_values, prev_gamma=None):\n",
    "        super().__init__()\n",
    "        self.expert_ffns        = expert_ffns\n",
    "        self.gamma_values       = gamma_values\n",
    "        self.previous_gamma     = prev_gamma or gamma_values.copy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1) plain softmax\n",
    "        gamma_t    = torch.tensor(list(self.gamma_values.values()), dtype=torch.float32)\n",
    "        gamma_soft = F.softmax(gamma_t, dim=0)\n",
    "\n",
    "        # 2) weighted expert outputs\n",
    "        outs = {\n",
    "            e: ffn(x) * gamma_soft[i]\n",
    "            for i, (e, ffn) in enumerate(self.expert_ffns.items())\n",
    "        }\n",
    "        weighted_sum = sum(outs.values())\n",
    "\n",
    "        # 3) entropy regularization\n",
    "        ent_loss = entropy_regularization(gamma_soft)\n",
    "\n",
    "        # 4) KL penalty vs previous\n",
    "        prev_t   = torch.tensor(list(self.previous_gamma.values()), dtype=torch.float32)\n",
    "        kl_prev  = kl_divergence(gamma_soft, prev_t)\n",
    "\n",
    "        # 5) gating loss vs uniform\n",
    "        n = len(gamma_soft)\n",
    "        uniform = torch.full((n,), 1.0 / n)\n",
    "        gate_l  = kl_divergence(gamma_soft, uniform)\n",
    "\n",
    "        # 6) RL loss vs uniform prior\n",
    "        rl_l    = kl_divergence(gamma_soft, uniform)\n",
    "\n",
    "        # 7) update previous\n",
    "        self.previous_gamma = self.gamma_values.copy()\n",
    "\n",
    "        # 8) total loss\n",
    "        total = (\n",
    "            torch.mean(weighted_sum)\n",
    "            + 0.1  * ent_loss\n",
    "            + 0.01 * kl_prev\n",
    "            + 0.05 * gate_l\n",
    "            + 0.05 * rl_l\n",
    "        )\n",
    "\n",
    "        # 9) update gamma values\n",
    "        losses = {e: total.item() for e in self.expert_ffns}\n",
    "        self.gamma_values = update_gamma_values(self.gamma_values, losses)\n",
    "\n",
    "        return total, weighted_sum, ent_loss, kl_prev, gate_l, rl_l\n",
    "\n",
    "# === Initialize and run ===\n",
    "gamma_init = {name: 1.0 for name in experts}\n",
    "router = MoCaERouterWithGatingAndRL(\n",
    "    {n: experts[n][\"ffn\"] for n in experts},\n",
    "    gamma_init\n",
    ")\n",
    "\n",
    "def process_input():\n",
    "    for name, v in experts.items():\n",
    "        df = v[\"train_data\"]\n",
    "        if df.empty:\n",
    "            print(f\"Skipping {name}\")\n",
    "            continue\n",
    "        emb = torch.tensor(df.values, dtype=torch.float32)\n",
    "        tot, ws, ent, klp, gl, rl = router(emb)\n",
    "        print(f\"{name}: Loss={tot.item():.4f}, Ent={ent:.4f}, KL={klp:.4f}, Gate={gl:.4f}, RL={rl:.4f}\")\n",
    "\n",
    "process_input()\n",
    "\n",
    "def save_embeddings():\n",
    "    agg = {}\n",
    "    for name, v in experts.items():\n",
    "        df = v[\"train_data\"]\n",
    "        if df.empty: continue\n",
    "        emb = torch.tensor(df.values, dtype=torch.float32)\n",
    "        _, ws, *_ = router(emb)\n",
    "        agg[name] = ws.detach().cpu().numpy()\n",
    "    out = '/workspace/Dataset/aggregated_embeddings'\n",
    "    os.makedirs(out, exist_ok=True)\n",
    "    np.save(os.path.join(out, 'aggregated_embeddings.npy'), agg)\n",
    "    print(\"Saved aggregated embeddings.\")\n",
    "\n",
    "save_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2fa8d3-1a90-4151-baa1-65cdc744659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the aggregated embeddings\n",
    "def check_aggregated_embeddings_shape(file_path):\n",
    "    \"\"\"Load the aggregated embeddings and print their shape.\"\"\"\n",
    "    # Load the embeddings from the saved .npy file\n",
    "    aggregated_embeddings = np.load(file_path, allow_pickle=True).item()\n",
    "    \n",
    "    # Print the shape of each expert's aggregated embedding\n",
    "    for expert, embedding in aggregated_embeddings.items():\n",
    "        print(f\"Shape of {expert}'s aggregated embedding: {embedding.shape}\")\n",
    "\n",
    "# Path to the saved aggregated embeddings file\n",
    "aggregated_embeddings_file = '/kaggle/input/worksapce/workspace/orkspace/Dataset/aggregated_embeddings/aggregated_embeddings.npy'\n",
    "\n",
    "# Check the shape of the aggregated embeddings\n",
    "check_aggregated_embeddings_shape(aggregated_embeddings_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2335e0a-e329-4d81-8b73-925abffb7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# --------------------\n",
    "# Config & Paths\n",
    "# --------------------\n",
    "expert_configs = {\n",
    "    \"alpaca\": {\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/Alpaca/Alpaca_Train.json\"\n",
    "    },\n",
    "    \"beavertails\": {\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/BeaverTails/BeaverTails_Train.csv\"\n",
    "    },\n",
    "    \"truthfulqa\": {\n",
    "        \"train_data\": \"/kaggle/input/worksapce/orkspace/Dataset/TruthfulQA/TruthfulQA_Train.csv\"\n",
    "    },\n",
    "    \n",
    "}\n",
    "EMBEDDINGS_FILE = '/workspace/Dataset/aggregated_embeddings/aggregated_embeddings.npy'\n",
    "\n",
    "# --------------------\n",
    "# Label Loader with Safe Fallback\n",
    "# --------------------\n",
    "def load_labels(expert_name, label_col='label'):\n",
    "    path = expert_configs[expert_name]['train_data']\n",
    "    if path is None:\n",
    "        raise KeyError(f\"No train_data path for {expert_name}\")\n",
    "    df = pd.read_json(path) if path.endswith('.json') else pd.read_csv(path)\n",
    "    if label_col in df.columns:\n",
    "        return df[label_col].values\n",
    "    # Try inferring label column: integer dtype with few unique values\n",
    "    int_cols = [c for c in df.columns if pd.api.types.is_integer_dtype(df[c])]\n",
    "    for c in int_cols:\n",
    "        if df[c].nunique() < len(df) / 2:\n",
    "            print(f\"Info: Using inferred label column '{c}' for {expert_name}\")\n",
    "            return df[c].values\n",
    "    # No suitable label found\n",
    "    raise KeyError(f\"No label column found for {expert_name} in {path}\")\n",
    "\n",
    "# --------------------\n",
    "# Calibration & Scoring Metrics\n",
    "# --------------------\n",
    "\n",
    "def compute_ece(probs, labels, n_bins=10):\n",
    "    bins = np.linspace(0,1,n_bins+1)\n",
    "    confidences = np.max(probs, axis=1)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    acc = (preds == labels).astype(float)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
    "        if mask.any():\n",
    "            ece += abs(confidences[mask].mean() - acc[mask].mean()) * mask.sum() / len(labels)\n",
    "    return ece\n",
    "\n",
    "\n",
    "def compute_brier(probs, labels):\n",
    "    N, C = probs.shape\n",
    "    true_onehot = np.zeros_like(probs)\n",
    "    true_onehot[np.arange(N), labels] = 1\n",
    "    return np.mean(np.sum((probs - true_onehot)**2, axis=1))\n",
    "\n",
    "\n",
    "def temperature_scale(probs, temperature=1.0):\n",
    "    logits = np.log(np.clip(probs, 1e-12, 1.0)) / temperature\n",
    "    exp = np.exp(logits)\n",
    "    return exp / exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "# --------------------\n",
    "# Zero-Shot & Few-Shot Evaluation\n",
    "# --------------------\n",
    "\n",
    "def eval_zero_shot(embeddings, labels, temp=1.0):\n",
    "    # Inference timing\n",
    "    start = time.time()\n",
    "    logits = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    probs = torch.softmax(logits, dim=1).numpy()\n",
    "    infer_time = time.time() - start\n",
    "\n",
    "    # Metrics\n",
    "    ece = compute_ece(probs, labels)\n",
    "    ece_t = compute_ece(temperature_scale(probs, temp), labels)\n",
    "    brier = compute_brier(probs, labels)\n",
    "\n",
    "    return {\n",
    "        'ECE': round(ece,4),\n",
    "        'ECE-t': round(ece_t,4),\n",
    "        'Brier': round(brier,4),\n",
    "        'Inference_Time_s': round(infer_time,4),\n",
    "        'Train_Time_s': 0.0,\n",
    "        'Train_Memory_MB': 0.0\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_few_shot(embeddings, labels, epochs=5, temp=1.0, device='cpu'):\n",
    "    X = torch.tensor(embeddings, dtype=torch.float32).to(device)\n",
    "    y = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "    num_classes = len(np.unique(labels))\n",
    "    model = nn.Linear(embeddings.shape[1], num_classes).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training timing & memory\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = crit(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_time = time.time() - t0\n",
    "    train_mem = psutil.Process(os.getpid()).memory_info().rss / 1024**2\n",
    "\n",
    "    # Inference\n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "    infer_time = time.time() - t1\n",
    "\n",
    "    # Metrics\n",
    "    ece = compute_ece(probs, labels)\n",
    "    ece_t = compute_ece(temperature_scale(probs, temp), labels)\n",
    "    brier = compute_brier(probs, labels)\n",
    "\n",
    "    return {\n",
    "        'ECE': round(ece,4),\n",
    "        'ECE-t': round(ece_t,4),\n",
    "        'Brier': round(brier,4),\n",
    "        'Inference_Time_s': round(infer_time,4),\n",
    "        'Train_Time_s': round(train_time,4),\n",
    "        'Train_Memory_MB': round(train_mem,4)\n",
    "    }\n",
    "\n",
    "# --------------------\n",
    "# Main Loop\n",
    "# --------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    agg = np.load(EMBEDDINGS_FILE, allow_pickle=True).item()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    for expert, emb in agg.items():\n",
    "        print(f\"--- {expert.upper()} ---\")\n",
    "        try:\n",
    "            labels = load_labels(expert)\n",
    "        except KeyError as e:\n",
    "            print(f\"Skipping '{expert}': {e}\")\n",
    "            continue\n",
    "\n",
    "        zero = eval_zero_shot(emb, labels)\n",
    "        few = eval_few_shot(emb, labels, epochs=5, device=device)\n",
    "\n",
    "        print(\"Zero-Shot Metrics:\")\n",
    "        for k,v in zero.items(): print(f\"  {k}: {v}\")\n",
    "        print(\"Few-Shot Metrics:\")\n",
    "        for k,v in few.items(): print(f\"  {k}: {v}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd06c23-8290-484a-ba83-1da398a205f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
